{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjgrP2uCWJa3"
   },
   "source": [
    "# GPU in colab\n",
    "First, you'll need to enable GPUs for the notebook:\n",
    "*   Navigate to Editâ†’Notebook Settings\n",
    "*   select GPU from the Hardware Accelerator drop-down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5090,
     "status": "ok",
     "timestamp": 1651061788474,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "16747943028598227166"
     },
     "user_tz": -60
    },
    "id": "vUjWOpB_WDi0",
    "outputId": "b48c2025-860c-4459-b61b-0d5067d5bb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xIaaiJsWzcz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gH7ZkS7llf09"
   },
   "source": [
    "# Exercise 1\n",
    "In notebook 3, was is reasonable to stop the training after 5 epochs? \n",
    "We will check that. Your tasks are:\n",
    "\n",
    "1) Import the Fashion MNIST dataset.\n",
    "\n",
    "2) Create the same neural network used in Notebook 3. \n",
    "\n",
    "3) Traing it until it overfits (accuracy on test becumes smaller than the one on the training dataset).\n",
    "\n",
    "4) Then plot the history (loss and accuracy curves). \n",
    "\n",
    "5) Evaluate your model\n",
    "\n",
    "What is the maximum validation accuracy that you obtained? How many epochs did you train your network for?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ooO3shguGTQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnhz010EmPre"
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Now build your own model for MNIST, experiment with \n",
    "- the number of nodes in the hidden layers, \n",
    "- the number of hidden layers, \n",
    "- the size of the learning rate.\n",
    "- activation functions in hidden layers, e.g. ReLu, sigmoid, tanh.\n",
    "- different optimizers: Adam, Adagrad, Nadam\n",
    "\n",
    "Here are some observations:\n",
    "\n",
    "- Underfitting occurs when there are too few neurons in the hidden layers \n",
    "- Too many neurons in the hidden layers may result in overfitting\n",
    "- The optimal number of nodes of the hidden layer is usually between the size of the input and size of the output layers.\n",
    "- One hidden layer is sufficient for the large majority of problems.\n",
    "- Adding more hidden layers slowers down the learning process (the convergence of SGD is slower). \n",
    "\n",
    "RULE-OF-THUMBS\n",
    "\n",
    "Number of hidden layers equals one; and the number of neurons in that layer is the mean of the neurons in the input and output layers.\n",
    "\n",
    "In general choosing the right architecture of the network depends on the data so you need to experiment!\n",
    "\n",
    "Note down the best accuracy you can get.  \n",
    "\n",
    "Make and plot the confusion matrix for your best result. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bAwShpKuPti"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-1f0ruhpJI8"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "Load the CIFAR10 data set by \n",
    "\n",
    "``tf.keras.datasets.cifar10.load_data()``\n",
    "\n",
    "1. Check the dimensionality of the data\n",
    "2. Visualise the data. \n",
    "2. Preprocess data so that the y values are categorical, and re-scale the data by dividing it by 255 (if needed).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6uVa2IbuSBI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZ3aGpa3p4Mk"
   },
   "source": [
    "# Exercise 4\n",
    "\n",
    "Build a Feedforward Neural Network for the CIFAR10 problem. Train it, print the training and validation loss/accuracy curves. \n",
    "\n",
    "What is your best accuracy score? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBjl3HJ62ikH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZoCozywsphl2ELZ6+eLvI",
   "collapsed_sections": [],
   "name": "Session1-Notebook4-ANNKerasExercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
